<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>repograph.entities.build.builder API documentation</title>
<meta name="description" content="RepographBuilder generates a populated Repograph from inspect4py JSON output." />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>repograph.entities.build.builder</code></h1>
</header>
<section id="section-intro">
<p>RepographBuilder generates a populated Repograph from inspect4py JSON output.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
RepographBuilder generates a populated Repograph from inspect4py JSON output.
&#34;&#34;&#34;
# Base imports
import logging
import os
from typing import Callable, Dict, Set, List, Optional, Tuple, Union

# Pip imports
from py2neo import Transaction
from requirements.requirement import Requirement

# Build entity imports
from repograph.entities.build.exceptions import RepographBuildError
from repograph.entities.graph.service import GraphService

# Models imports
from repograph.entities.graph.models.nodes import (
    Argument,
    Class,
    Docstring,
    DocstringArgument,
    DocstringRaises,
    DocstringReturnValue,
    Directory,
    Module,
    Function,
    License,
    Package,
    README,
    Repository,
    ReturnValue,
    Variable,
)
from repograph.entities.graph.models.relationships import (
    Calls,
    Contains,
    Describes,
    Documents,
    HasArgument,
    HasFunction,
    HasMethod,
    Imports,
    LicensedBy,
    Returns,
    Requires, Extends,
)

# Utility imports
from repograph.utils.builtin import PYTHON_BUILT_IN_FUNCTIONS
from repograph.utils.json import (
    JSONDict,
    convert_dependencies_map_to_set,
    parse_min_max_line_numbers,
    marshall_json_to_string,
)
from repograph.entities.build.utils import find_node_object_by_name
from repograph.utils.paths import (
    strip_file_path_prefix,
    is_root_folder,
    get_path_name,
    get_path_root,
    get_path_parent,
    get_package_parent_and_name,
    get_module_and_object_from_canonical_object_name,
)

ADDITIONAL_KEYS = [&#34;requirements&#34;, &#34;directory_tree&#34;, &#34;license&#34;, &#34;readme_files&#34;]

INIT = &#34;__init__&#34;

log = logging.getLogger(&#34;repograph.repograph_builder&#34;)


class RepographBuilder:
    &#34;&#34;&#34;
    Generates a Repograph from inspect4py output.
    &#34;&#34;&#34;

    def __init__(
        self,
        summarize: Optional[Callable[[Function], str]],
        base_path: str,
        graph_name: str,
        graph: GraphService,
        tx: Transaction,
    ) -&gt; None:
        &#34;&#34;&#34;Constructor

        Args:
            summarize (Optional[Callable[[Function], str]]): The optional summarization method.
            base_path (str): The base path directory
            graph_name (str): The name of the graph nodes are being added to.
        &#34;&#34;&#34;
        # The base directory path used for normalizing paths
        self.base_path = base_path

        # Name of the graph. Used for calls to the graph service
        self.graph_name = graph_name

        # The name of the repository
        self.repository_name = &#34;&#34;

        # Transaction to use for calls to the graph service
        self.tx = tx

        # Graph service
        self.graph: GraphService = graph

        # The optional summarization function
        self.summarize: Optional[Callable[[Function], str]] = summarize

        # Mapping of paths to Directory (or the Repository) object
        self.directories: Dict[str, Union[Repository, Directory]] = dict()

        # Mapping of paths/pacakge names to modules
        self.modules: Dict[str, Module] = dict()

        # Mapping of Module objects to Classes/Function objects
        self.module_objects: Dict[Module, List[Union[Class, Function]]] = dict()

        # Mapping Module dependencies for retrospective parsing
        self.dependencies: List[Tuple[List[JSONDict], Module]] = []

        # Mapping Class extends for retrospective parsing
        self.extends: List[Tuple[Class, Module, JSONDict]] = []

        # The objects a given Module depends on/imports
        self.module_dependencies: Dict[Module, List[Union[Class, Module, Function]]] = dict()

        # Module imports
        self.module_imports: Dict[Module, Set[str]] = dict()

        # Packages from requirements file
        self.requirements: Dict[str, Package] = dict()

        # Mapping of built-in functions that have been called in the repository
        self.called_builtin_functions: Dict[str, Function] = dict()

    def _parse_repository(
        self,
        path: str,
        metadata: JSONDict = None,
        software_type: str = None,
        directory_info: List[JSONDict] = None,
    ) -&gt; Repository:
        &#34;&#34;&#34;Parses information about the repository, i.e. the root,
        itself.

        Args:
            path (str): The path of the repository.
            metadata (Optional[JSONDict]): Optional metadata describing the repository.
            directory_info (Optional[List[JSONDict]]): Optional list of directories to parse

        Returns:
            Repository: The created Repository node
        &#34;&#34;&#34;
        is_package = False
        modules = []

        # Parse files within this folder, as Python files may be contained in the repository root
        if directory_info:
            modules, is_package = self._parse_files_in_directory(directory_info)

        if metadata:
            repository = Repository.create_from_metadata(
                path, metadata, is_package, software_type, path
            )
        else:
            repository = Repository(
                name=path,
                is_root_package=is_package,
                type=software_type,
                repository_name=path,
            )

        self.repository_name = repository.name

        self.graph.add(repository, tx=self.tx, graph_name=self.graph_name)
        self.directories[repository.name] = repository

        # Parse each extracted module
        for module, file_info in modules:
            # If repository root is a package, add the full canonical name as such
            if repository.is_root_package:
                module = module.update_canonical_name(
                    f&#34;{repository.name}.{module.name}&#34;
                )

            # Now parse the contents of the  module
            self._parse_module_contents(module, file_info)

            # Create a relationship between the Repository and the Module
            relationship = Contains(repository, module, self.repository_name)
            self.graph.add(module, tx=self.tx, graph_name=self.graph_name)
            self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

            # Finally add the module to the list of stored modules
            self.modules[module.canonical_name] = module
            self.modules[module.path] = module

        return repository

    def _parse_requirements(
        self, requirements: List[Requirement], repository: Repository
    ) -&gt; None:
        &#34;&#34;&#34;Parses information extracted from the requirements.txt file.

        Args:
            requirements (Optional[JSONDict]): The JSON describing the requirements.
                                               May be None if not found.
            repository (Repository): The parent Repository node for any created
                                     Package nodes.
        &#34;&#34;&#34;
        if not requirements:
            log.warning(&#34;No requirements information found.&#34;)
        else:
            log.info(&#34;Parsing requirements information...&#34;)
            for requirement in requirements:
                package = Package.create_from_external_dependency(
                    requirement.name, self.repository_name
                )

                relationship = Requires(
                    repository,
                    package,
                    self.repository_name,
                    specifications=list(map(lambda spec: &#34; &#34;.join(spec), requirement.specs)),
                )

                self.graph.add(package, tx=self.tx, graph_name=self.graph_name)
                self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)
                self.requirements[requirement.name] = package

    def _parse_license(
        self, licenses: Optional[JSONDict], repository: Repository
    ) -&gt; None:
        &#34;&#34;&#34;Parses extracted license information.

        Args:
            licenses (Optional[JSONDict]): The JSON describing the extracted licenses.
            repository (Repository): The parent Repository node for any created License nodes.

        Returns:
            None
        &#34;&#34;&#34;
        if not licenses:
            log.warning(&#34;No license information found.&#34;)
        else:
            log.info(&#34;Parsing repository license information.&#34;)
            detected_types = licenses.get(&#34;detected_type&#34;, [])
            if len(detected_types) == 0:
                log.warning(&#34;No license types detected&#34;)

            for detected in detected_types:
                for detected_type, confidence in detected.items():
                    license_node = License(
                        text=licenses.get(&#34;extracted_text&#34;, None),
                        license_type=detected_type,
                        confidence=(float(confidence.strip(&#34;%&#34;)) / 100),
                        graph_name=self.graph_name,
                        repository_name=self.repository_name,
                    )
                    relationship = LicensedBy(
                        repository, license_node, self.repository_name
                    )
                    self.graph.add(license_node, tx=self.tx, graph_name=self.graph_name)
                    self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

    def _parse_readme(self, info: JSONDict):
        &#34;&#34;&#34;Parse README files in the repository

        Args:
            info (JSONDict): README files information.

        Returns:
            None
        &#34;&#34;&#34;
        log.info(&#34;Parsing README files...&#34;)
        if not info:
            log.warning(&#34;No READMEs found!&#34;)
            return

        readmes = []
        relationships = []
        from pathlib import Path

        for path, content in info.items():
            path = str(Path(path).relative_to(self.base_path))
            readme = README(
                path=path,
                content=content,
                graph_name=self.graph_name,
                repository_name=self.repository_name,
            )
            readmes.append(readme)

            parent_path = get_path_parent(path)
            parent = self.directories.get(parent_path, None)

            if parent:
                relationship = Contains(parent, readme, self.repository_name)
                relationships.append(relationship)
            else:
                log.error(&#34;Couldn&#39;t find parent for README at path: %s&#34;, path)

        self.graph.add(*readmes, tx=self.tx, graph_name=self.graph_name)
        self.graph.add(*relationships, tx=self.tx, graph_name=self.graph_name)

    def _get_parent_directory(self, parent_path: str) -&gt; Directory:
        &#34;&#34;&#34;Retrieves the parent directory for supplied path.

        Recursively creates missing parent directories and adds relationship.

        Args:
            parent_path (str): The path the parent directory to retrieve

        Returns:
            Type[Directory]: The parent Directory.
        &#34;&#34;&#34;

        def add_parents_recursively(child: Directory) -&gt; None:
            &#34;&#34;&#34;Recursively adds further missing parent directories

            Args:
                child (Directory): The immediate parent directory to the true child directory.
                                   i.e. the Directory with the path of parent_path.

            Returns:
                None
            &#34;&#34;&#34;
            parent = self.directories.get(child.parent_path, None)

            if not parent:
                parent = Directory(child.parent_path, self.repository_name)
                relationship = Contains(parent, child, self.repository_name)
                self.graph.add(parent, tx=self.tx, graph_name=self.graph_name)
                self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)
                self.directories[parent.path] = parent
                return add_parents_recursively(parent)
            else:
                parent_relationship = Contains(parent, child, self.repository_name)
                self.graph.add(child, tx=self.tx, graph_name=self.graph_name)
                self.graph.add(
                    parent_relationship, tx=self.tx, graph_name=self.graph_name
                )
                return

        # Attempt to get the parent directory from the list of created directories.
        existing_parent = self.directories.get(parent_path, None)
        if existing_parent:
            return existing_parent

        # If it doesn&#39;t exist create a new Directory and then call the recursive function.
        new_parent = Directory(parent_path, self.repository_name)
        self.graph.add(new_parent, tx=self.tx, graph_name=self.graph_name)
        self.directories[new_parent.path] = new_parent
        add_parents_recursively(new_parent)

        return new_parent

    def _create_canonical_package_name(self, directory_path: str) -&gt; str:
        &#34;&#34;&#34;Create canonical package name for a directory path

        Args:
            directory_path (str): The starting directory.

        Returns:
            str: The canonical package name.
        &#34;&#34;&#34;
        parts = [get_path_name(directory_path)]
        parent = get_path_parent(directory_path)

        while parent != &#34;&#34;:
            parent_node = self.directories.get(parent, None)

            if isinstance(parent_node, Package) or (
                isinstance(parent_node, Repository) and parent_node.is_root_package
            ):
                parts = [get_path_name(parent)] + parts
                parent = get_path_parent(parent)
            else:
                return &#34;.&#34;.join(parts)

        return &#34;.&#34;.join(parts)

    def _parse_directory(
        self,
        directory_name: str,
        directory_info: List[JSONDict],
        index: int,
        total: int,
    ) -&gt; None:
        &#34;&#34;&#34;Parse a directory

        Args:
            directory_name (str): The name of the directory.
            directory_info (JSONDict): The directory information.
            index (int): The index of the directory within the repository.
            total (int): The total number of directories within the repository.
        &#34;&#34;&#34;
        directory_path = strip_file_path_prefix(directory_name)
        log.debug(&#34;Parsing directory &#39;%s&#39; (%d/%d)&#34;, directory_path, index + 1, total)

        # Parse each file within the directory, update is_package
        # with result (whether file is __init__.py), and add to list
        # of Files.
        modules, is_package = self._parse_files_in_directory(directory_info)

        # Get the parent directory
        parent = self._get_parent_directory(get_path_parent(directory_path))

        # If an __init__.py was found, create a Package node,
        # otherwise create a Directory node.
        if is_package:
            canonical_name = self._create_canonical_package_name(directory_path)
            directory = Package.create_from_directory(
                directory_path, canonical_name, self.repository_name
            )
        else:
            directory = Directory(directory_path, self.repository_name)

        # Add the list of created directories, the directory node,
        # and the relationship to its parent, to the Repograph.
        self.directories[directory.path] = directory
        relationship = Contains(parent, directory, self.repository_name)
        self.graph.add(parent, tx=self.tx, graph_name=self.graph_name)
        self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

        # Parse each extracted module
        for module, file_info in modules:
            # If parent is a package, add the full canonical path name and add to modules.
            if isinstance(directory, Package):
                module = module.update_canonical_name(
                    f&#34;{directory.canonical_name}.{module.name}&#34;
                )
                self.modules[module.canonical_name] = module

            # Now parse the contents of the module.
            self._parse_module_contents(module, file_info)

            # Create a relationship between the Directory and the Module.
            relationship = Contains(directory, module, self.repository_name)
            self.graph.add(module, tx=self.tx, graph_name=self.graph_name)
            self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

            # Finally add the module to the list of stored modules.
            self.modules[module.path] = module
            self.modules[module.canonical_name] = module

    def _parse_files_in_directory(
        self, directory_info: List[JSONDict]
    ) -&gt; Tuple[List[Tuple[Module, JSONDict]], bool]:
        &#34;&#34;&#34;Parses files within a directory into Python Module nodes.

        Args:
            directory_info (List[JSONDict]): The list of JSONDict objects to parse.

        Returns:
            Tuple[List[Tuple[Module, JSONDict]], bool]: The list of parsed Module nodes and whether
                                                        the enclosing directory is a package.
        &#34;&#34;&#34;
        is_package = False
        modules = []

        for file_index, file_info in enumerate(directory_info):
            module = self._parse_module(file_info, file_index, len(directory_info))
            is_package = is_package or module.name == INIT
            modules.append((module, file_info))

        return modules, is_package

    def _parse_module(self, file_info: JSONDict, index: int, total: int) -&gt; Module:
        &#34;&#34;&#34;Parses a Python module with a parent directory.

        Args:
            file_info (JSONDict): The information about the file to parse.
            index (int): The index of the Module within the parent Folder.
            total (int): The total number of Modules within the parent Folder.

        Returns:
            bool: Whether Module is an __init__.py.
        &#34;&#34;&#34;
        log.debug(
            &#34;--&gt; Parsing file `%s` (%d/%d)&#34;,
            file_info[&#34;file&#34;][&#34;fileNameBase&#34;],
            index + 1,
            total,
        )

        module = Module(
            name=file_info[&#34;file&#34;][&#34;fileNameBase&#34;],
            canonical_name=file_info[&#34;file&#34;][&#34;fileNameBase&#34;],
            path=file_info[&#34;file&#34;][&#34;path&#34;],
            parent_path=get_path_parent(file_info[&#34;file&#34;][&#34;path&#34;]),
            extension=file_info[&#34;file&#34;][&#34;extension&#34;],
            is_test=file_info.get(&#34;is_test&#34;, False),
            repository_name=self.repository_name,
        )

        self.module_objects[module] = []

        return module

    def _parse_module_contents(self, module: Module, file_info: JSONDict) -&gt; None:
        &#34;&#34;&#34;Parse the contents of the module.

        This includes functions/methods and classes.

        Args:
            module (Module): Module object to link extracted functions/classes to.
            file_info (JSONDict): The JSONDict of information containing information about
                                  the module.

        Returns:
            None
        &#34;&#34;&#34;
        self._parse_functions_and_methods(file_info.get(&#34;functions&#34;, {}), module)
        self._parse_classes(file_info.get(&#34;classes&#34;, {}), module)

        if &#34;dependencies&#34; in file_info:
            self.dependencies.append((file_info[&#34;dependencies&#34;], module))
            self.module_imports[module] = convert_dependencies_map_to_set(
                file_info[&#34;dependencies&#34;]
            )

    def _parse_functions_and_methods(
        self,
        functions_info: JSONDict,
        parent: Union[Module, Class],
        methods: bool = False,
    ) -&gt; None:
        &#34;&#34;&#34;Parses function/method information into Function/Method nodes and adds links
        to the parent File/Class node.

        Args:
            functions_info (JSONDict): JSON dictionary containing the function information.
            parent (Union[Module, Class]): Parent File or Class node.
            methods (bool): Whether to create Method nodes rather than Function nodes.
        &#34;&#34;&#34;
        for name, info in functions_info.items():
            # Get min-max line numbers
            min_lineno, max_lineno = parse_min_max_line_numbers(info)
            if not min_lineno or not max_lineno:
                log.warning(&#34;Missing line number information for function &#39;%s&#39;&#34;, name)

            # Serialise the AST
            ast = info.get(&#34;ast&#34;)
            if ast:
                ast_string = marshall_json_to_string(ast)
                if not ast:
                    log.error(&#34;Couldn&#39;t serialise AST for function %s&#34;, name)
            else:
                log.warning(&#34;AST missing for function %s&#34;, name)
                ast_string = None

            # Check source_code is available
            source_code = info.get(&#34;source_code&#34;, None)
            if not source_code:
                log.warning(&#34;Source code missing for function %s&#34;, name)

            # Create Function Node
            if methods:
                function_type = str(Function.FunctionType.METHOD.value)
            else:
                function_type = str(Function.FunctionType.FUNCTION.value)

            function = Function(
                name=name,
                type=function_type,
                canonical_name=f&#34;{parent.canonical_name}.{name}&#34;,
                source_code=source_code,
                ast=ast_string,
                min_line_number=min_lineno,
                max_line_number=max_lineno,
                repository_name=self.repository_name,
            )

            # Add to graph
            self.graph.add(function, tx=self.tx, graph_name=self.graph_name)

            # Parse the docstring for the function
            self._parse_docstring(info.get(&#34;doc&#34;, {}), function)

            # Create HasFunction Relationship
            if methods:
                relationship = HasMethod(parent, function, self.repository_name)
            else:
                relationship = HasFunction(parent, function, self.repository_name)
            self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

            # If parent is a module, add to the module_objects set
            if isinstance(parent, Module):
                self.module_objects[parent].append(function)

            # Parse arguments and create Argument nodes
            self._parse_arguments(
                info.get(&#34;args&#34;, []), info.get(&#34;annotated_arg_types&#34;, {}), function
            )

            # Parse return values and create ReturnValue nodes
            self._parse_return_values(
                info.get(&#34;returns&#34;, []),
                info.get(&#34;annotated_return_type&#34;, &#34;Any&#34;),
                function,
            )

    def _parse_classes(self, class_info: Dict, parent: Module) -&gt; None:
        &#34;&#34;&#34;Parses class information into Class nodes and
        adds links to parent File node.

        Args:
            class_info (Dict): Dictionary containing class information.
            parent (Module): Parent File node.
        &#34;&#34;&#34;
        for name, info in class_info.items():
            min_lineno, max_lineno = parse_min_max_line_numbers(info)
            class_node = Class(
                name=name,
                canonical_name=f&#34;{parent.canonical_name}.{name}&#34;,
                min_line_number=min_lineno,
                max_line_number=max_lineno,
                repository_name=self.repository_name,
            )
            relationship = Contains(parent, class_node, self.repository_name)
            self.graph.add(class_node, tx=self.tx, graph_name=self.graph_name)
            self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

            # Add to module objects set
            self.module_objects[parent].append(class_node)

            # Save extends info for retrospective parsing
            self.extends.append((class_node, parent, info.get(&#34;extend&#34;, [])))

            # Parse docstring
            self._parse_docstring(info.get(&#34;doc&#34;, {}), class_node)

            # Parse method info inside class if available
            methods_info = info.get(&#34;methods&#34;, None)
            if methods_info:
                self._parse_functions_and_methods(
                    methods_info, class_node, methods=True
                )

    def _parse_arguments(
        self,
        args_list: List[str],
        annotated_arg_types: Dict[str, str],
        parent: Function,
    ) -&gt; None:
        &#34;&#34;&#34;Parse arguments from method information.

        Args:
            args_list (List[str]): The list of argument names.
            annotated_arg_types (Dict[str, str]): The annotated argument types.
            parent (Function): The parent function the arguments belong to.
        &#34;&#34;&#34;
        arg_types = annotated_arg_types
        for arg in args_list:
            if arg_types:
                arg_type = arg_types.get(arg, &#34;Any&#34;)
            else:
                arg_type = &#34;Any&#34;

            argument = Argument(
                name=arg, type=arg_type, repository_name=self.repository_name
            )
            relationship = HasArgument(parent, argument, self.repository_name)
            self.graph.add(argument, tx=self.tx, graph_name=self.graph_name)
            self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

    def _parse_return_values(
        self, return_values: List[List[str]], annotated_type: str, parent: Function
    ) -&gt; None:
        &#34;&#34;&#34;Parse return values from function/method information.

        Args:
            return_values (List[str]): The list of return value names.
            annotated_type (Dict[str, str]): The annotated return value types.
            parent (Function): The parent function the return values belong to.
        &#34;&#34;&#34;
        if len(return_values) &gt; 1:
            return_type = &#34;Any&#34;
        elif len(return_values) == 1:
            return_type = annotated_type
        else:
            return

        def parse(values):
            for value in values:
                if isinstance(value, list):
                    parse(value)
                elif isinstance(value, str):
                    return_value = ReturnValue(
                        name=value,
                        type=return_type,
                        repository_name=self.repository_name,
                    )
                    relationship = Returns(parent, return_value, self.repository_name)
                    self.graph.add(return_value, tx=self.tx, graph_name=self.graph_name)
                    self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)
                else:
                    log.error(
                        &#34;Unexpected return value type `%s` for function `%s`&#34;,
                        type(value),
                        parent.name,
                    )

        parse(return_values)

    def _parse_docstring(
        self, docstring_info: Optional[JSONDict], parent: Union[Function, Class]
    ) -&gt; None:
        &#34;&#34;&#34;Parse docstring information for function or class

        Args:
            docstring_info (JSONDict): The JSONDict containing docstring information.
            parent (Union[Function, Class): The parent node the docstring describes.

        Returns:
            None
        &#34;&#34;&#34;
        # Return immediately depending on whether Class/Function, if docstring info
        # provided, and whether summarization enabled.
        if isinstance(parent, Class):
            if not docstring_info or not bool(docstring_info):
                log.debug(f&#34;No docstring information for class {parent.name}&#34;)
                return
        elif isinstance(parent, Function):
            if (not docstring_info or not bool(docstring_info)) and not self.summarize:
                log.debug(f&#34;No docstring information for {parent.name}&#34;)
                return
        else:
            return

        # Initialise empty arrays for storing created nodes/relationships
        nodes = []
        relationships = []

        # If the summarization flag is set and parent is a Function (not a Class),
        # call the function summarizer.
        if self.summarize and isinstance(parent, Function):
            summary = self.summarize(parent)
        else:
            summary = None

        # Parse docstring
        docstring = Docstring(
            summarization=summary,
            short_description=docstring_info.get(&#34;short_description&#34;, None),
            long_description=docstring_info.get(&#34;long_description&#34;, None),
            repository_name=self.repository_name,
        )
        relationship = Documents(docstring, parent, self.repository_name)
        nodes.append(docstring)
        relationships.append(relationship)

        if isinstance(parent, Class):
            # Parse docstring arguments
            for arg, arg_info in docstring_info.get(&#34;args&#34;, {}).items():
                docstring_arg = DocstringArgument(
                    name=arg,
                    type=arg_info.get(&#34;type_name&#34;, None),
                    description=arg_info.get(&#34;description&#34;, None),
                    is_optional=arg_info.get(&#34;is_optional&#34;, False),
                    default=arg_info.get(&#34;default&#34;, None),
                    repository_name=self.repository_name,
                )
                relationship = Describes(docstring, docstring_arg, self.repository_name)
                nodes.append(docstring_arg)
                relationships.append(relationship)

            if &#34;returns&#34; in docstring_info:
                # Parse docstring return values
                returns_info = docstring_info.get(&#34;returns&#34;, {})
                docstring_return_value = DocstringReturnValue(
                    name=returns_info.get(&#34;return_name&#34;, None),
                    description=returns_info.get(&#34;description&#34;, None),
                    type=returns_info.get(&#34;type_name&#34;, None),
                    is_generator=returns_info.get(&#34;is_generator&#34;, False),
                    repository_name=self.repository_name,
                )
                relationship = Describes(
                    docstring, docstring_return_value, self.repository_name
                )
                nodes.append(docstring_return_value)
                relationships.append(relationship)

            # Parse docstring raises
            for raises in docstring_info.get(&#34;raises&#34;, []):
                docstring_raises = DocstringRaises(
                    description=raises.get(&#34;description&#34;, None),
                    type=raises.get(&#34;type_name&#34;, None),
                    repository_name=self.repository_name,
                )
                relationship = Describes(
                    docstring, docstring_raises, self.repository_name
                )
                nodes.append(docstring_raises)
                relationships.append(relationship)

        # Add nodes and relationships to graph
        self.graph.add(*nodes, tx=self.tx, graph_name=self.graph_name)
        self.graph.add(*relationships, tx=self.tx, graph_name=self.graph_name)

    def _parse_dependencies(self) -&gt; None:  # noqa: C901
        &#34;&#34;&#34;Parse the dependencies between Modules.

        Returns:
            None
        &#34;&#34;&#34;
        log.info(&#34;Parsing dependencies...&#34;)
        unresolved_dependencies = []

        # Iterate through dependencies for each required module
        for dependency_info, module in self.dependencies:
            # Create an entry in the module_dependencies dict,
            # so we can keep track of found objects.
            self.module_dependencies[module] = []

            # Iterate through each dependency in the module
            for dependency in dependency_info:
                # Check whether a module object or module itself is being imported
                if &#34;from_module&#34; in dependency:
                    imports_module = False
                else:
                    imports_module = True

                # Get the imported object (either module or object)
                imported_object = dependency[&#34;import&#34;]
                source_module = dependency.get(&#34;from_module&#34;, imported_object)

                # Find the module
                if dependency[&#34;type&#34;] == &#34;internal&#34;:
                    imported_module = self.modules.get(source_module, None)
                    # If we can&#39;t find the module, it could be a relative import so use the package
                    # components if the importing module&#39;s canonical name.
                    if not imported_module:
                        added = []
                        for part in module.canonical_name.split(&#34;.&#34;):
                            added.append(part)
                            imported_module = self.modules.get(
                                &#34;.&#34;.join(added + [source_module]), None
                            )
                            if imported_module:
                                break
                    # Finally if we still haven&#39;t found the imported module, it may be the case that
                    # the object is being imported from the __init__ of a package.
                    if not imported_module:
                        imported_module = self.modules.get(
                            f&#34;{source_module}.__init__&#34;, None
                        )

                else:
                    imported_module = self.modules.get(source_module, None)
                    if not imported_module:
                        imported_module = self.modules.get(
                            f&#34;{source_module}.__init__&#34;, None
                        )

                # If importing a module directly....
                if imports_module:
                    # ...and it already exists create the relationship
                    if imported_module:
                        self.graph.add(
                            Imports(module, imported_module, self.graph_name),
                            tx=self.tx,
                            graph_name=self.graph_name,
                        )
                        self.module_dependencies[module].append(imported_module)
                    # ...and if it doesn&#39;t recursively create it
                    else:
                        source_module, missing = self._calculate_missing_packages(
                            source_module
                        )

                        if source_module == &#34;&#34;:
                            child = self._create_missing_nodes(missing)
                        elif source_module in self.requirements:
                            child = self._create_missing_nodes(
                                missing, parent=self.requirements[source_module]
                            )
                        else:
                            child = self._create_missing_nodes(
                                missing, parent=self.modules[source_module]
                            )

                        # TODO: If not NONE?
                        self.graph.add(
                            Imports(module, child, self.repository_name),
                            tx=self.tx,
                            graph_name=self.graph_name,
                        )
                        self.module_dependencies[module].append(child)

                # If importing a class, function, etc...
                else:
                    # ...or it already exists then create the relationship
                    if imported_module:
                        if imported_module.inferred:
                            if imported_object[0].isupper():
                                imported_object = Class(
                                    name=imported_object,
                                    canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                                    repository_name=self.repository_name,
                                    inferred=True,
                                )
                            else:
                                imported_object = Function(
                                    name=imported_object,
                                    canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                                    type=str(Function.FunctionType.FUNCTION.value),
                                    repository_name=self.repository_name,
                                    inferred=True,
                                )

                            self.graph.add(
                                Imports(module, imported_object, self.graph_name),
                                Imports(
                                    imported_module, imported_object, self.graph_name
                                ),
                                tx=self.tx,
                                graph_name=self.graph_name,
                            )

                            self.module_dependencies[imported_module].append(
                                imported_object
                            )
                            self.module_dependencies[module].append(imported_object)
                        else:
                            module_objects = self.module_objects.get(
                                imported_module, []
                            )
                            if not module_objects:
                                unresolved_dependencies.append(
                                    (
                                        module,
                                        imported_module,
                                        imported_object,
                                        dependency,
                                    )
                                )
                                continue

                            # Filter the module objects for only those with the imported name
                            matching_objects = [
                                obj
                                for obj in module_objects
                                if obj is not None and obj.name == imported_object
                            ]

                            # If no matches, log an error and move onto the next dependency
                            if len(matching_objects) == 0:
                                unresolved_dependencies.append(
                                    (
                                        module,
                                        imported_module,
                                        imported_object,
                                        dependency,
                                    )
                                )
                                continue

                            # If more than one match we log this inconsistency,
                            # but add all import relationships
                            if len(matching_objects) &gt; 1:
                                log.warning(
                                    &#34;More than 1 matching object found in import.&#34;
                                )

                            for match in matching_objects:
                                self.graph.add(
                                    Imports(module, match, self.repository_name),
                                    tx=self.tx,
                                )
                                self.module_dependencies[module].append(match)
                    # ...and if it doesn&#39;t recursively create it
                    else:
                        if imported_object[0].isupper():
                            imported_object = Class(
                                name=imported_object,
                                canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                                repository_name=self.repository_name,
                                inferred=True,
                            )
                        else:
                            imported_object = Function(
                                name=imported_object,
                                canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                                type=str(Function.FunctionType.FUNCTION.value),
                                repository_name=self.repository_name,
                                inferred=True,
                            )

                        source_module, missing = self._calculate_missing_packages(
                            source_module
                        )

                        if source_module == &#34;&#34;:
                            self._create_missing_nodes(missing, import_object=imported_object)
                        elif source_module in self.requirements:
                            self._create_missing_nodes(
                                missing,
                                parent=self.requirements[source_module],
                                import_object=imported_object,
                            )
                        else:
                            self._create_missing_nodes(
                                missing,
                                parent=self.modules[source_module],
                                import_object=imported_object,
                            )

                        self.graph.add(
                            Imports(module, imported_object, self.repository_name),
                            tx=self.tx,
                            graph_name=self.graph_name,
                        )
                        self.module_dependencies[module].append(imported_object)

        # Second pass on unresolved dependencies that are likely to be imports of other modules.
        unresolved = unresolved_dependencies
        while len(unresolved) != 0:
            remaining = []
            for (
                module,
                imported_module,
                imported_object,
                dependency,
            ) in unresolved:
                # Check the module objects of the imported module first
                module_objects = self.module_objects.get(imported_module, [])
                matching_objects = [
                    obj
                    for obj in module_objects
                    if obj is not None and obj.name == imported_object
                ]
                if len(matching_objects) &gt; 0:
                    for match in matching_objects:
                        self.graph.add(
                            Imports(module, match, self.repository_name), tx=self.tx
                        )
                        self.module_dependencies[module].append(match)
                    continue

                # Then check the module imports of the imported module
                module_imports = self.module_dependencies.get(imported_module, [])
                matching_objects = [
                    obj
                    for obj in module_imports
                    if obj is not None and obj.name == imported_object
                ]
                if len(matching_objects) &gt; 0:
                    for match in matching_objects:
                        self.graph.add(
                            Imports(module, match, self.repository_name), tx=self.tx
                        )
                        self.module_dependencies[module].append(match)
                    continue

                remaining.append((module, imported_module, imported_object, dependency))

            if len(remaining) == len(unresolved):
                unresolved = remaining
                break
            else:
                unresolved = remaining

        # Finally, infer any remaining objects
        for (
            module,
            imported_module,
            imported_object,
            dependency,
        ) in unresolved:
            if imported_object.isupper() or imported_object.startswith(&#34;__&#34;):
                imported_object = Variable(
                    name=imported_object,
                    canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                    inferred=True,
                    repository_name=self.repository_name,
                )
            elif imported_object[0].isupper():
                imported_object = Class(
                    name=imported_object,
                    canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                    repository_name=self.repository_name,
                    inferred=True,
                )
            else:
                imported_object = Function(
                    name=imported_object,
                    canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                    type=str(Function.FunctionType.FUNCTION.value),
                    repository_name=self.repository_name,
                    inferred=True,
                )

            self.graph.add(
                Contains(imported_module, imported_object, self.repository_name),
                Imports(module, imported_object, self.repository_name),
                tx=self.tx,
                graph_name=self.graph_name,
            )
            self.module_objects[imported_module].append(imported_object)
            self.module_dependencies[module].append(imported_object)

    def _calculate_missing_packages(self, source_module: str) -&gt; Tuple[str, List[str]]:
        &#34;&#34;&#34;Calculates missing packages for a given import source Module.

        Checks both parsed Modules and Repository level requirements.

        Args:
            source_module (str): The canonical name of the source module.

        Returns:
            str: Any pre-existing source package.
            List[str]: Missing packages/modules.
        &#34;&#34;&#34;
        missing = []
        while (
            source_module not in self.modules
            and source_module not in self.requirements
            and source_module != &#34;&#34;
        ):
            parent, child = get_package_parent_and_name(source_module)
            missing.append(child)
            source_module = parent

        return source_module, missing

    def _create_missing_nodes(
        self,
        missing: List[str],
        parent: Package = None,
        import_object: Union[Class, Function] = None,
    ) -&gt; Union[Module, Function]:
        &#34;&#34;&#34;Create missing nodes.

        Args:
            missing (List[str]):
            parent (Package): The parent Package. Optional.
            import_object (Union[Class, Function]): The Class or Function being imported from the

        Returns:
            Union[Module, Function]: The child Node.
        &#34;&#34;&#34;
        nodes = []
        relationships = []
        child = None

        for index, m in enumerate(missing):
            if index == len(missing) - 1 and len(missing) &gt; 1:
                new = Module(
                    name=m, repository_name=self.repository_name, inferred=True
                )
                child = new
            else:
                new = Package(
                    name=m,
                    canonical_name=f&#34;{parent.canonical_name}.{m}&#34; if parent else m,
                    parent_package=parent.canonical_name if parent else &#34;&#34;,
                    external=True,
                    repository_name=self.repository_name,
                    inferred=True,
                )

                if index == len(missing) - 1:
                    child = new

            if parent:
                relationships.append(Contains(parent, new, self.repository_name))

            parent = new
            nodes.append(new)

        # If we have an import_object, but the parent is a Package, we check to see if an __init__
        # module exists for the package. If not, we create an __init__ Module as this is actually
        # where the import_object is being imported from.
        if import_object and parent and isinstance(parent, Package):
            init_name = f&#34;{parent.canonical_name}.__init__&#34;
            if init_name in self.modules:
                parent = self.modules[init_name]
            else:
                new = Module.create_init_module(
                    parent.canonical_name, self.repository_name
                )
                relationships.append(Contains(parent, new, self.repository_name))
                self.modules[init_name] = new
                self.module_dependencies[new] = []
                parent = new

        # If we have an import object, create a Contains relationship with the parent module.
        if import_object:
            relationships.append(Contains(parent, import_object, self.repository_name))
            child = import_object

        if child == None and parent:
            child = parent

        # Add the created nodes and relationships to the Repograph.
        self.graph.add(*nodes, tx=self.tx, graph_name=self.graph_name)
        self.graph.add(*relationships, tx=self.tx, graph_name=self.graph_name)

        return child

    def _parse_call_graph(self, call_graph: Optional[JSONDict]) -&gt; None:
        &#34;&#34;&#34;Parse the call graph extracted by inspect4py.

        Args:
            call_graph (Optional[JSONDict]): The call graph.

        Returns:
            None
        &#34;&#34;&#34;
        if not call_graph:
            log.error(&#34;No call graph provided!&#34;)
            return

        for directory, files in call_graph.items():
            for file_name, file_info in files.items():
                module = self.modules.get(file_name)
                if not module:
                    log.error(&#34;Couldn&#39;t find existing Module node. Skipping!&#34;)
                    continue

                module_objects = self.module_objects.get(module, [])
                module_imports = self.module_imports.get(module, set())
                module_dependencies = self.module_dependencies.get(module, [])

                # Parse body calls
                self._parse_calls(
                    module,
                    file_info.get(&#34;body&#34;, {}),
                    module_objects,
                    module_imports,
                    module_dependencies,
                )

                # For each function described in the call graph, parse these calls
                for function_name, function_calls in file_info.get(
                    &#34;functions&#34;, {}
                ).items():
                    function = find_node_object_by_name(module_objects, function_name)
                    self._parse_calls(
                        module,
                        function_calls,
                        module_objects,
                        module_imports,
                        module_dependencies,
                        caller=function,
                    )

        # Add called builtin functions to the graph
        self.graph.add(
            *self.called_builtin_functions.values(),
            tx=self.tx,
            graph_name=self.graph_name,
        )

    def _parse_calls(
        self,
        parent_module: Module,
        call_info: Optional[JSONDict],
        module_objects: List[any],
        module_imports: Set[str],
        module_dependencies: List[any],
        caller: Optional[Function] = None,
    ) -&gt; None:
        &#34;&#34;&#34;Parse the call graph for a particular module.

        Args:
            parent_module (Module): The parent module.
            call_info (Optional[JSONDict]): The call info.
            caller (Optional[Function): An optional specific function that the call info is for.
        Returns:
            None
        &#34;&#34;&#34;
        if not call_info:
            return

        for call in call_info.get(&#34;local&#34;, []):
            module, function = get_module_and_object_from_canonical_object_name(call)
            matching_objects_in_module = find_node_object_by_name(
                module_objects, function
            )

            # If the call is to an imported function...
            if call in module_imports:
                matching_imports = find_node_object_by_name(module_dependencies, call)
                relationship = Calls(
                    caller if caller else parent_module,
                    matching_imports,
                    self.repository_name,
                )
            # ...or if the call is to a built-in function...
            elif call in PYTHON_BUILT_IN_FUNCTIONS:
                if function in self.called_builtin_functions:
                    function_node = self.called_builtin_functions[function]
                else:
                    function_node = Function(
                        name=function,
                        type=str(Function.FunctionType.FUNCTION.value),
                        builtin=True,
                        repository_name=self.repository_name,
                        inferred=True,
                    )
                    self.called_builtin_functions[function] = function_node

                # Create the relationship between the caller and the new function_node
                relationship = Calls(
                    caller if caller else parent_module,
                    function_node,
                    self.repository_name,
                )

            # ...or if the call is to a function defined in the module
            elif matching_objects_in_module:
                relationship = Calls(
                    caller if caller else parent_module,
                    matching_objects_in_module,
                    self.repository_name,
                )
            else:
                log.debug(&#34;Call to some other variable (%s). Ignoring.&#34;, call)
                relationship = None

            self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

    def _parse_extends(self) -&gt; None:
        &#34;&#34;&#34;Parse extends/super class information.

        Returns:
            None
        &#34;&#34;&#34;
        for class_node, module, extends_info in self.extends:
            for extends in extends_info:
                # Check first if the extended class is defined in the module
                matching_objects = [
                    obj
                    for obj in self.module_objects.get(module, [])
                    if
                    obj is not None and
                    (obj.name == extends or obj.canonical_name == extends) and
                    isinstance(obj, Class)
                ]

                if matching_objects:
                    for obj in matching_objects:
                        self.graph.add(
                            Extends(class_node, obj, self.graph_name),
                            tx=self.tx,
                            graph_name=self.graph_name
                        )
                    continue

                # Check if it&#39;s in the module imports
                matching_objects = [
                    obj
                    for obj in self.module_dependencies.get(module, [])
                    if
                    obj is not None and
                    (obj.name == extends or obj.canonical_name == extends) and
                    isinstance(obj, Class)
                ]

                if matching_objects:
                    for obj in matching_objects:
                        self.graph.add(
                            Extends(class_node, obj, self.graph_name),
                            tx=self.tx,
                            graph_name=self.graph_name
                        )
                    continue

                log.warning(&#34;Unable to find extends match&#34;)

    def build(
        self,
        directory_info: Optional[JSONDict],
        call_graph: Optional[JSONDict],
        requirements: List[Requirement] = None,
    ) -&gt; None:
        &#34;&#34;&#34;Build a repograph from directory_info JSON.

        Args:
            directory_info (JSONDict): Directory info JSON.
            call_graph (Optional[JSONDict]): The call graph JSON.
            requirements (List[Requirement], optional): Requirements to pass.

        Returns:
            Repograph

        Raises:
            RepographBuildError
        &#34;&#34;&#34;
        log.info(&#34;Building Repograph...&#34;)

        if not directory_info:
            log.error(&#34;Directory info is empty! Aborting!&#34;)
            raise RepographBuildError(&#34;Directory info is empty&#34;)

        # Pop off non-directory entries from the JSON, for parsing later
        _ = directory_info.pop(&#34;requirements&#34;, None)
        _ = directory_info.pop(&#34;directory_tree&#34;, None)
        licenses = directory_info.pop(&#34;license&#34;, None)
        readmes = directory_info.pop(&#34;readme_files&#34;, None)
        metadata = directory_info.pop(&#34;metadata&#34;, None)
        _ = directory_info.pop(&#34;software_invocation&#34;, None)
        software_type = directory_info.pop(&#34;software_type&#34;, None)
        _ = directory_info.pop(&#34;tests&#34;, None)

        # Create a sorted list of directory paths.py, as dictionaries are not
        # always sortable in Python.
        log.info(&#34;Sorting directories with hierarchical ordering...&#34;)
        directories = sorted(
            list(directory_info.keys()),
            key=lambda file: (os.path.dirname(file), os.path.basename(file)),
        )

        # Parse repository root folder if it exists, otherwise manually create
        # the repository node.
        path = strip_file_path_prefix(directories[0])
        self.repository_name = path

        if is_root_folder(path):
            directory = directories.pop(0)
            repository = self._parse_repository(
                path,
                directory_info=directory_info[directory],
                metadata=metadata,
                software_type=software_type,
            )
        else:
            repository = self._parse_repository(
                get_path_root(path), metadata=metadata, software_type=software_type
            )

        # Parse requirements
        self._parse_requirements(requirements, repository)

        # Parse license
        self._parse_license(licenses, repository)

        # Parse each directory
        log.info(&#34;Extracting information from directories...&#34;)
        for index, directory in enumerate(directories):
            self._parse_directory(
                directory, directory_info[directory], index, len(directories)
            )

        # Retrospectively parse module dependencies
        log.info(&#34;Parsing module dependencies...&#34;)
        self._parse_dependencies()

        # Parse the call list, now that most Nodes should be added to the graph
        log.info(&#34;Parsing call graph...&#34;)
        self._parse_call_graph(call_graph)

        # Parse extends relationships
        log.info(&#34;Parsing extends relationships...&#34;)
        self._parse_extends()

        # Parse READMEs
        self._parse_readme(readmes)

        log.info(&#34;Successfully built a Repograph!&#34;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="repograph.entities.build.builder.RepographBuilder"><code class="flex name class">
<span>class <span class="ident">RepographBuilder</span></span>
<span>(</span><span>summarize:Optional[Callable[[<a title="repograph.entities.graph.models.nodes.Function" href="../graph/models/nodes.html#repograph.entities.graph.models.nodes.Function">Function</a>],str]], base_path:str, graph_name:str, graph:<a title="repograph.entities.graph.service.GraphService" href="../graph/service.html#repograph.entities.graph.service.GraphService">GraphService</a>, tx:py2neo.database.Transaction)</span>
</code></dt>
<dd>
<div class="desc"><p>Generates a Repograph from inspect4py output.</p>
<p>Constructor</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>summarize</code></strong> :&ensp;<code>Optional[Callable[[Function], str]]</code></dt>
<dd>The optional summarization method.</dd>
<dt><strong><code>base_path</code></strong> :&ensp;<code>str</code></dt>
<dd>The base path directory</dd>
<dt><strong><code>graph_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the graph nodes are being added to.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class RepographBuilder:
    &#34;&#34;&#34;
    Generates a Repograph from inspect4py output.
    &#34;&#34;&#34;

    def __init__(
        self,
        summarize: Optional[Callable[[Function], str]],
        base_path: str,
        graph_name: str,
        graph: GraphService,
        tx: Transaction,
    ) -&gt; None:
        &#34;&#34;&#34;Constructor

        Args:
            summarize (Optional[Callable[[Function], str]]): The optional summarization method.
            base_path (str): The base path directory
            graph_name (str): The name of the graph nodes are being added to.
        &#34;&#34;&#34;
        # The base directory path used for normalizing paths
        self.base_path = base_path

        # Name of the graph. Used for calls to the graph service
        self.graph_name = graph_name

        # The name of the repository
        self.repository_name = &#34;&#34;

        # Transaction to use for calls to the graph service
        self.tx = tx

        # Graph service
        self.graph: GraphService = graph

        # The optional summarization function
        self.summarize: Optional[Callable[[Function], str]] = summarize

        # Mapping of paths to Directory (or the Repository) object
        self.directories: Dict[str, Union[Repository, Directory]] = dict()

        # Mapping of paths/pacakge names to modules
        self.modules: Dict[str, Module] = dict()

        # Mapping of Module objects to Classes/Function objects
        self.module_objects: Dict[Module, List[Union[Class, Function]]] = dict()

        # Mapping Module dependencies for retrospective parsing
        self.dependencies: List[Tuple[List[JSONDict], Module]] = []

        # Mapping Class extends for retrospective parsing
        self.extends: List[Tuple[Class, Module, JSONDict]] = []

        # The objects a given Module depends on/imports
        self.module_dependencies: Dict[Module, List[Union[Class, Module, Function]]] = dict()

        # Module imports
        self.module_imports: Dict[Module, Set[str]] = dict()

        # Packages from requirements file
        self.requirements: Dict[str, Package] = dict()

        # Mapping of built-in functions that have been called in the repository
        self.called_builtin_functions: Dict[str, Function] = dict()

    def _parse_repository(
        self,
        path: str,
        metadata: JSONDict = None,
        software_type: str = None,
        directory_info: List[JSONDict] = None,
    ) -&gt; Repository:
        &#34;&#34;&#34;Parses information about the repository, i.e. the root,
        itself.

        Args:
            path (str): The path of the repository.
            metadata (Optional[JSONDict]): Optional metadata describing the repository.
            directory_info (Optional[List[JSONDict]]): Optional list of directories to parse

        Returns:
            Repository: The created Repository node
        &#34;&#34;&#34;
        is_package = False
        modules = []

        # Parse files within this folder, as Python files may be contained in the repository root
        if directory_info:
            modules, is_package = self._parse_files_in_directory(directory_info)

        if metadata:
            repository = Repository.create_from_metadata(
                path, metadata, is_package, software_type, path
            )
        else:
            repository = Repository(
                name=path,
                is_root_package=is_package,
                type=software_type,
                repository_name=path,
            )

        self.repository_name = repository.name

        self.graph.add(repository, tx=self.tx, graph_name=self.graph_name)
        self.directories[repository.name] = repository

        # Parse each extracted module
        for module, file_info in modules:
            # If repository root is a package, add the full canonical name as such
            if repository.is_root_package:
                module = module.update_canonical_name(
                    f&#34;{repository.name}.{module.name}&#34;
                )

            # Now parse the contents of the  module
            self._parse_module_contents(module, file_info)

            # Create a relationship between the Repository and the Module
            relationship = Contains(repository, module, self.repository_name)
            self.graph.add(module, tx=self.tx, graph_name=self.graph_name)
            self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

            # Finally add the module to the list of stored modules
            self.modules[module.canonical_name] = module
            self.modules[module.path] = module

        return repository

    def _parse_requirements(
        self, requirements: List[Requirement], repository: Repository
    ) -&gt; None:
        &#34;&#34;&#34;Parses information extracted from the requirements.txt file.

        Args:
            requirements (Optional[JSONDict]): The JSON describing the requirements.
                                               May be None if not found.
            repository (Repository): The parent Repository node for any created
                                     Package nodes.
        &#34;&#34;&#34;
        if not requirements:
            log.warning(&#34;No requirements information found.&#34;)
        else:
            log.info(&#34;Parsing requirements information...&#34;)
            for requirement in requirements:
                package = Package.create_from_external_dependency(
                    requirement.name, self.repository_name
                )

                relationship = Requires(
                    repository,
                    package,
                    self.repository_name,
                    specifications=list(map(lambda spec: &#34; &#34;.join(spec), requirement.specs)),
                )

                self.graph.add(package, tx=self.tx, graph_name=self.graph_name)
                self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)
                self.requirements[requirement.name] = package

    def _parse_license(
        self, licenses: Optional[JSONDict], repository: Repository
    ) -&gt; None:
        &#34;&#34;&#34;Parses extracted license information.

        Args:
            licenses (Optional[JSONDict]): The JSON describing the extracted licenses.
            repository (Repository): The parent Repository node for any created License nodes.

        Returns:
            None
        &#34;&#34;&#34;
        if not licenses:
            log.warning(&#34;No license information found.&#34;)
        else:
            log.info(&#34;Parsing repository license information.&#34;)
            detected_types = licenses.get(&#34;detected_type&#34;, [])
            if len(detected_types) == 0:
                log.warning(&#34;No license types detected&#34;)

            for detected in detected_types:
                for detected_type, confidence in detected.items():
                    license_node = License(
                        text=licenses.get(&#34;extracted_text&#34;, None),
                        license_type=detected_type,
                        confidence=(float(confidence.strip(&#34;%&#34;)) / 100),
                        graph_name=self.graph_name,
                        repository_name=self.repository_name,
                    )
                    relationship = LicensedBy(
                        repository, license_node, self.repository_name
                    )
                    self.graph.add(license_node, tx=self.tx, graph_name=self.graph_name)
                    self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

    def _parse_readme(self, info: JSONDict):
        &#34;&#34;&#34;Parse README files in the repository

        Args:
            info (JSONDict): README files information.

        Returns:
            None
        &#34;&#34;&#34;
        log.info(&#34;Parsing README files...&#34;)
        if not info:
            log.warning(&#34;No READMEs found!&#34;)
            return

        readmes = []
        relationships = []
        from pathlib import Path

        for path, content in info.items():
            path = str(Path(path).relative_to(self.base_path))
            readme = README(
                path=path,
                content=content,
                graph_name=self.graph_name,
                repository_name=self.repository_name,
            )
            readmes.append(readme)

            parent_path = get_path_parent(path)
            parent = self.directories.get(parent_path, None)

            if parent:
                relationship = Contains(parent, readme, self.repository_name)
                relationships.append(relationship)
            else:
                log.error(&#34;Couldn&#39;t find parent for README at path: %s&#34;, path)

        self.graph.add(*readmes, tx=self.tx, graph_name=self.graph_name)
        self.graph.add(*relationships, tx=self.tx, graph_name=self.graph_name)

    def _get_parent_directory(self, parent_path: str) -&gt; Directory:
        &#34;&#34;&#34;Retrieves the parent directory for supplied path.

        Recursively creates missing parent directories and adds relationship.

        Args:
            parent_path (str): The path the parent directory to retrieve

        Returns:
            Type[Directory]: The parent Directory.
        &#34;&#34;&#34;

        def add_parents_recursively(child: Directory) -&gt; None:
            &#34;&#34;&#34;Recursively adds further missing parent directories

            Args:
                child (Directory): The immediate parent directory to the true child directory.
                                   i.e. the Directory with the path of parent_path.

            Returns:
                None
            &#34;&#34;&#34;
            parent = self.directories.get(child.parent_path, None)

            if not parent:
                parent = Directory(child.parent_path, self.repository_name)
                relationship = Contains(parent, child, self.repository_name)
                self.graph.add(parent, tx=self.tx, graph_name=self.graph_name)
                self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)
                self.directories[parent.path] = parent
                return add_parents_recursively(parent)
            else:
                parent_relationship = Contains(parent, child, self.repository_name)
                self.graph.add(child, tx=self.tx, graph_name=self.graph_name)
                self.graph.add(
                    parent_relationship, tx=self.tx, graph_name=self.graph_name
                )
                return

        # Attempt to get the parent directory from the list of created directories.
        existing_parent = self.directories.get(parent_path, None)
        if existing_parent:
            return existing_parent

        # If it doesn&#39;t exist create a new Directory and then call the recursive function.
        new_parent = Directory(parent_path, self.repository_name)
        self.graph.add(new_parent, tx=self.tx, graph_name=self.graph_name)
        self.directories[new_parent.path] = new_parent
        add_parents_recursively(new_parent)

        return new_parent

    def _create_canonical_package_name(self, directory_path: str) -&gt; str:
        &#34;&#34;&#34;Create canonical package name for a directory path

        Args:
            directory_path (str): The starting directory.

        Returns:
            str: The canonical package name.
        &#34;&#34;&#34;
        parts = [get_path_name(directory_path)]
        parent = get_path_parent(directory_path)

        while parent != &#34;&#34;:
            parent_node = self.directories.get(parent, None)

            if isinstance(parent_node, Package) or (
                isinstance(parent_node, Repository) and parent_node.is_root_package
            ):
                parts = [get_path_name(parent)] + parts
                parent = get_path_parent(parent)
            else:
                return &#34;.&#34;.join(parts)

        return &#34;.&#34;.join(parts)

    def _parse_directory(
        self,
        directory_name: str,
        directory_info: List[JSONDict],
        index: int,
        total: int,
    ) -&gt; None:
        &#34;&#34;&#34;Parse a directory

        Args:
            directory_name (str): The name of the directory.
            directory_info (JSONDict): The directory information.
            index (int): The index of the directory within the repository.
            total (int): The total number of directories within the repository.
        &#34;&#34;&#34;
        directory_path = strip_file_path_prefix(directory_name)
        log.debug(&#34;Parsing directory &#39;%s&#39; (%d/%d)&#34;, directory_path, index + 1, total)

        # Parse each file within the directory, update is_package
        # with result (whether file is __init__.py), and add to list
        # of Files.
        modules, is_package = self._parse_files_in_directory(directory_info)

        # Get the parent directory
        parent = self._get_parent_directory(get_path_parent(directory_path))

        # If an __init__.py was found, create a Package node,
        # otherwise create a Directory node.
        if is_package:
            canonical_name = self._create_canonical_package_name(directory_path)
            directory = Package.create_from_directory(
                directory_path, canonical_name, self.repository_name
            )
        else:
            directory = Directory(directory_path, self.repository_name)

        # Add the list of created directories, the directory node,
        # and the relationship to its parent, to the Repograph.
        self.directories[directory.path] = directory
        relationship = Contains(parent, directory, self.repository_name)
        self.graph.add(parent, tx=self.tx, graph_name=self.graph_name)
        self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

        # Parse each extracted module
        for module, file_info in modules:
            # If parent is a package, add the full canonical path name and add to modules.
            if isinstance(directory, Package):
                module = module.update_canonical_name(
                    f&#34;{directory.canonical_name}.{module.name}&#34;
                )
                self.modules[module.canonical_name] = module

            # Now parse the contents of the module.
            self._parse_module_contents(module, file_info)

            # Create a relationship between the Directory and the Module.
            relationship = Contains(directory, module, self.repository_name)
            self.graph.add(module, tx=self.tx, graph_name=self.graph_name)
            self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

            # Finally add the module to the list of stored modules.
            self.modules[module.path] = module
            self.modules[module.canonical_name] = module

    def _parse_files_in_directory(
        self, directory_info: List[JSONDict]
    ) -&gt; Tuple[List[Tuple[Module, JSONDict]], bool]:
        &#34;&#34;&#34;Parses files within a directory into Python Module nodes.

        Args:
            directory_info (List[JSONDict]): The list of JSONDict objects to parse.

        Returns:
            Tuple[List[Tuple[Module, JSONDict]], bool]: The list of parsed Module nodes and whether
                                                        the enclosing directory is a package.
        &#34;&#34;&#34;
        is_package = False
        modules = []

        for file_index, file_info in enumerate(directory_info):
            module = self._parse_module(file_info, file_index, len(directory_info))
            is_package = is_package or module.name == INIT
            modules.append((module, file_info))

        return modules, is_package

    def _parse_module(self, file_info: JSONDict, index: int, total: int) -&gt; Module:
        &#34;&#34;&#34;Parses a Python module with a parent directory.

        Args:
            file_info (JSONDict): The information about the file to parse.
            index (int): The index of the Module within the parent Folder.
            total (int): The total number of Modules within the parent Folder.

        Returns:
            bool: Whether Module is an __init__.py.
        &#34;&#34;&#34;
        log.debug(
            &#34;--&gt; Parsing file `%s` (%d/%d)&#34;,
            file_info[&#34;file&#34;][&#34;fileNameBase&#34;],
            index + 1,
            total,
        )

        module = Module(
            name=file_info[&#34;file&#34;][&#34;fileNameBase&#34;],
            canonical_name=file_info[&#34;file&#34;][&#34;fileNameBase&#34;],
            path=file_info[&#34;file&#34;][&#34;path&#34;],
            parent_path=get_path_parent(file_info[&#34;file&#34;][&#34;path&#34;]),
            extension=file_info[&#34;file&#34;][&#34;extension&#34;],
            is_test=file_info.get(&#34;is_test&#34;, False),
            repository_name=self.repository_name,
        )

        self.module_objects[module] = []

        return module

    def _parse_module_contents(self, module: Module, file_info: JSONDict) -&gt; None:
        &#34;&#34;&#34;Parse the contents of the module.

        This includes functions/methods and classes.

        Args:
            module (Module): Module object to link extracted functions/classes to.
            file_info (JSONDict): The JSONDict of information containing information about
                                  the module.

        Returns:
            None
        &#34;&#34;&#34;
        self._parse_functions_and_methods(file_info.get(&#34;functions&#34;, {}), module)
        self._parse_classes(file_info.get(&#34;classes&#34;, {}), module)

        if &#34;dependencies&#34; in file_info:
            self.dependencies.append((file_info[&#34;dependencies&#34;], module))
            self.module_imports[module] = convert_dependencies_map_to_set(
                file_info[&#34;dependencies&#34;]
            )

    def _parse_functions_and_methods(
        self,
        functions_info: JSONDict,
        parent: Union[Module, Class],
        methods: bool = False,
    ) -&gt; None:
        &#34;&#34;&#34;Parses function/method information into Function/Method nodes and adds links
        to the parent File/Class node.

        Args:
            functions_info (JSONDict): JSON dictionary containing the function information.
            parent (Union[Module, Class]): Parent File or Class node.
            methods (bool): Whether to create Method nodes rather than Function nodes.
        &#34;&#34;&#34;
        for name, info in functions_info.items():
            # Get min-max line numbers
            min_lineno, max_lineno = parse_min_max_line_numbers(info)
            if not min_lineno or not max_lineno:
                log.warning(&#34;Missing line number information for function &#39;%s&#39;&#34;, name)

            # Serialise the AST
            ast = info.get(&#34;ast&#34;)
            if ast:
                ast_string = marshall_json_to_string(ast)
                if not ast:
                    log.error(&#34;Couldn&#39;t serialise AST for function %s&#34;, name)
            else:
                log.warning(&#34;AST missing for function %s&#34;, name)
                ast_string = None

            # Check source_code is available
            source_code = info.get(&#34;source_code&#34;, None)
            if not source_code:
                log.warning(&#34;Source code missing for function %s&#34;, name)

            # Create Function Node
            if methods:
                function_type = str(Function.FunctionType.METHOD.value)
            else:
                function_type = str(Function.FunctionType.FUNCTION.value)

            function = Function(
                name=name,
                type=function_type,
                canonical_name=f&#34;{parent.canonical_name}.{name}&#34;,
                source_code=source_code,
                ast=ast_string,
                min_line_number=min_lineno,
                max_line_number=max_lineno,
                repository_name=self.repository_name,
            )

            # Add to graph
            self.graph.add(function, tx=self.tx, graph_name=self.graph_name)

            # Parse the docstring for the function
            self._parse_docstring(info.get(&#34;doc&#34;, {}), function)

            # Create HasFunction Relationship
            if methods:
                relationship = HasMethod(parent, function, self.repository_name)
            else:
                relationship = HasFunction(parent, function, self.repository_name)
            self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

            # If parent is a module, add to the module_objects set
            if isinstance(parent, Module):
                self.module_objects[parent].append(function)

            # Parse arguments and create Argument nodes
            self._parse_arguments(
                info.get(&#34;args&#34;, []), info.get(&#34;annotated_arg_types&#34;, {}), function
            )

            # Parse return values and create ReturnValue nodes
            self._parse_return_values(
                info.get(&#34;returns&#34;, []),
                info.get(&#34;annotated_return_type&#34;, &#34;Any&#34;),
                function,
            )

    def _parse_classes(self, class_info: Dict, parent: Module) -&gt; None:
        &#34;&#34;&#34;Parses class information into Class nodes and
        adds links to parent File node.

        Args:
            class_info (Dict): Dictionary containing class information.
            parent (Module): Parent File node.
        &#34;&#34;&#34;
        for name, info in class_info.items():
            min_lineno, max_lineno = parse_min_max_line_numbers(info)
            class_node = Class(
                name=name,
                canonical_name=f&#34;{parent.canonical_name}.{name}&#34;,
                min_line_number=min_lineno,
                max_line_number=max_lineno,
                repository_name=self.repository_name,
            )
            relationship = Contains(parent, class_node, self.repository_name)
            self.graph.add(class_node, tx=self.tx, graph_name=self.graph_name)
            self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

            # Add to module objects set
            self.module_objects[parent].append(class_node)

            # Save extends info for retrospective parsing
            self.extends.append((class_node, parent, info.get(&#34;extend&#34;, [])))

            # Parse docstring
            self._parse_docstring(info.get(&#34;doc&#34;, {}), class_node)

            # Parse method info inside class if available
            methods_info = info.get(&#34;methods&#34;, None)
            if methods_info:
                self._parse_functions_and_methods(
                    methods_info, class_node, methods=True
                )

    def _parse_arguments(
        self,
        args_list: List[str],
        annotated_arg_types: Dict[str, str],
        parent: Function,
    ) -&gt; None:
        &#34;&#34;&#34;Parse arguments from method information.

        Args:
            args_list (List[str]): The list of argument names.
            annotated_arg_types (Dict[str, str]): The annotated argument types.
            parent (Function): The parent function the arguments belong to.
        &#34;&#34;&#34;
        arg_types = annotated_arg_types
        for arg in args_list:
            if arg_types:
                arg_type = arg_types.get(arg, &#34;Any&#34;)
            else:
                arg_type = &#34;Any&#34;

            argument = Argument(
                name=arg, type=arg_type, repository_name=self.repository_name
            )
            relationship = HasArgument(parent, argument, self.repository_name)
            self.graph.add(argument, tx=self.tx, graph_name=self.graph_name)
            self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

    def _parse_return_values(
        self, return_values: List[List[str]], annotated_type: str, parent: Function
    ) -&gt; None:
        &#34;&#34;&#34;Parse return values from function/method information.

        Args:
            return_values (List[str]): The list of return value names.
            annotated_type (Dict[str, str]): The annotated return value types.
            parent (Function): The parent function the return values belong to.
        &#34;&#34;&#34;
        if len(return_values) &gt; 1:
            return_type = &#34;Any&#34;
        elif len(return_values) == 1:
            return_type = annotated_type
        else:
            return

        def parse(values):
            for value in values:
                if isinstance(value, list):
                    parse(value)
                elif isinstance(value, str):
                    return_value = ReturnValue(
                        name=value,
                        type=return_type,
                        repository_name=self.repository_name,
                    )
                    relationship = Returns(parent, return_value, self.repository_name)
                    self.graph.add(return_value, tx=self.tx, graph_name=self.graph_name)
                    self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)
                else:
                    log.error(
                        &#34;Unexpected return value type `%s` for function `%s`&#34;,
                        type(value),
                        parent.name,
                    )

        parse(return_values)

    def _parse_docstring(
        self, docstring_info: Optional[JSONDict], parent: Union[Function, Class]
    ) -&gt; None:
        &#34;&#34;&#34;Parse docstring information for function or class

        Args:
            docstring_info (JSONDict): The JSONDict containing docstring information.
            parent (Union[Function, Class): The parent node the docstring describes.

        Returns:
            None
        &#34;&#34;&#34;
        # Return immediately depending on whether Class/Function, if docstring info
        # provided, and whether summarization enabled.
        if isinstance(parent, Class):
            if not docstring_info or not bool(docstring_info):
                log.debug(f&#34;No docstring information for class {parent.name}&#34;)
                return
        elif isinstance(parent, Function):
            if (not docstring_info or not bool(docstring_info)) and not self.summarize:
                log.debug(f&#34;No docstring information for {parent.name}&#34;)
                return
        else:
            return

        # Initialise empty arrays for storing created nodes/relationships
        nodes = []
        relationships = []

        # If the summarization flag is set and parent is a Function (not a Class),
        # call the function summarizer.
        if self.summarize and isinstance(parent, Function):
            summary = self.summarize(parent)
        else:
            summary = None

        # Parse docstring
        docstring = Docstring(
            summarization=summary,
            short_description=docstring_info.get(&#34;short_description&#34;, None),
            long_description=docstring_info.get(&#34;long_description&#34;, None),
            repository_name=self.repository_name,
        )
        relationship = Documents(docstring, parent, self.repository_name)
        nodes.append(docstring)
        relationships.append(relationship)

        if isinstance(parent, Class):
            # Parse docstring arguments
            for arg, arg_info in docstring_info.get(&#34;args&#34;, {}).items():
                docstring_arg = DocstringArgument(
                    name=arg,
                    type=arg_info.get(&#34;type_name&#34;, None),
                    description=arg_info.get(&#34;description&#34;, None),
                    is_optional=arg_info.get(&#34;is_optional&#34;, False),
                    default=arg_info.get(&#34;default&#34;, None),
                    repository_name=self.repository_name,
                )
                relationship = Describes(docstring, docstring_arg, self.repository_name)
                nodes.append(docstring_arg)
                relationships.append(relationship)

            if &#34;returns&#34; in docstring_info:
                # Parse docstring return values
                returns_info = docstring_info.get(&#34;returns&#34;, {})
                docstring_return_value = DocstringReturnValue(
                    name=returns_info.get(&#34;return_name&#34;, None),
                    description=returns_info.get(&#34;description&#34;, None),
                    type=returns_info.get(&#34;type_name&#34;, None),
                    is_generator=returns_info.get(&#34;is_generator&#34;, False),
                    repository_name=self.repository_name,
                )
                relationship = Describes(
                    docstring, docstring_return_value, self.repository_name
                )
                nodes.append(docstring_return_value)
                relationships.append(relationship)

            # Parse docstring raises
            for raises in docstring_info.get(&#34;raises&#34;, []):
                docstring_raises = DocstringRaises(
                    description=raises.get(&#34;description&#34;, None),
                    type=raises.get(&#34;type_name&#34;, None),
                    repository_name=self.repository_name,
                )
                relationship = Describes(
                    docstring, docstring_raises, self.repository_name
                )
                nodes.append(docstring_raises)
                relationships.append(relationship)

        # Add nodes and relationships to graph
        self.graph.add(*nodes, tx=self.tx, graph_name=self.graph_name)
        self.graph.add(*relationships, tx=self.tx, graph_name=self.graph_name)

    def _parse_dependencies(self) -&gt; None:  # noqa: C901
        &#34;&#34;&#34;Parse the dependencies between Modules.

        Returns:
            None
        &#34;&#34;&#34;
        log.info(&#34;Parsing dependencies...&#34;)
        unresolved_dependencies = []

        # Iterate through dependencies for each required module
        for dependency_info, module in self.dependencies:
            # Create an entry in the module_dependencies dict,
            # so we can keep track of found objects.
            self.module_dependencies[module] = []

            # Iterate through each dependency in the module
            for dependency in dependency_info:
                # Check whether a module object or module itself is being imported
                if &#34;from_module&#34; in dependency:
                    imports_module = False
                else:
                    imports_module = True

                # Get the imported object (either module or object)
                imported_object = dependency[&#34;import&#34;]
                source_module = dependency.get(&#34;from_module&#34;, imported_object)

                # Find the module
                if dependency[&#34;type&#34;] == &#34;internal&#34;:
                    imported_module = self.modules.get(source_module, None)
                    # If we can&#39;t find the module, it could be a relative import so use the package
                    # components if the importing module&#39;s canonical name.
                    if not imported_module:
                        added = []
                        for part in module.canonical_name.split(&#34;.&#34;):
                            added.append(part)
                            imported_module = self.modules.get(
                                &#34;.&#34;.join(added + [source_module]), None
                            )
                            if imported_module:
                                break
                    # Finally if we still haven&#39;t found the imported module, it may be the case that
                    # the object is being imported from the __init__ of a package.
                    if not imported_module:
                        imported_module = self.modules.get(
                            f&#34;{source_module}.__init__&#34;, None
                        )

                else:
                    imported_module = self.modules.get(source_module, None)
                    if not imported_module:
                        imported_module = self.modules.get(
                            f&#34;{source_module}.__init__&#34;, None
                        )

                # If importing a module directly....
                if imports_module:
                    # ...and it already exists create the relationship
                    if imported_module:
                        self.graph.add(
                            Imports(module, imported_module, self.graph_name),
                            tx=self.tx,
                            graph_name=self.graph_name,
                        )
                        self.module_dependencies[module].append(imported_module)
                    # ...and if it doesn&#39;t recursively create it
                    else:
                        source_module, missing = self._calculate_missing_packages(
                            source_module
                        )

                        if source_module == &#34;&#34;:
                            child = self._create_missing_nodes(missing)
                        elif source_module in self.requirements:
                            child = self._create_missing_nodes(
                                missing, parent=self.requirements[source_module]
                            )
                        else:
                            child = self._create_missing_nodes(
                                missing, parent=self.modules[source_module]
                            )

                        # TODO: If not NONE?
                        self.graph.add(
                            Imports(module, child, self.repository_name),
                            tx=self.tx,
                            graph_name=self.graph_name,
                        )
                        self.module_dependencies[module].append(child)

                # If importing a class, function, etc...
                else:
                    # ...or it already exists then create the relationship
                    if imported_module:
                        if imported_module.inferred:
                            if imported_object[0].isupper():
                                imported_object = Class(
                                    name=imported_object,
                                    canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                                    repository_name=self.repository_name,
                                    inferred=True,
                                )
                            else:
                                imported_object = Function(
                                    name=imported_object,
                                    canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                                    type=str(Function.FunctionType.FUNCTION.value),
                                    repository_name=self.repository_name,
                                    inferred=True,
                                )

                            self.graph.add(
                                Imports(module, imported_object, self.graph_name),
                                Imports(
                                    imported_module, imported_object, self.graph_name
                                ),
                                tx=self.tx,
                                graph_name=self.graph_name,
                            )

                            self.module_dependencies[imported_module].append(
                                imported_object
                            )
                            self.module_dependencies[module].append(imported_object)
                        else:
                            module_objects = self.module_objects.get(
                                imported_module, []
                            )
                            if not module_objects:
                                unresolved_dependencies.append(
                                    (
                                        module,
                                        imported_module,
                                        imported_object,
                                        dependency,
                                    )
                                )
                                continue

                            # Filter the module objects for only those with the imported name
                            matching_objects = [
                                obj
                                for obj in module_objects
                                if obj is not None and obj.name == imported_object
                            ]

                            # If no matches, log an error and move onto the next dependency
                            if len(matching_objects) == 0:
                                unresolved_dependencies.append(
                                    (
                                        module,
                                        imported_module,
                                        imported_object,
                                        dependency,
                                    )
                                )
                                continue

                            # If more than one match we log this inconsistency,
                            # but add all import relationships
                            if len(matching_objects) &gt; 1:
                                log.warning(
                                    &#34;More than 1 matching object found in import.&#34;
                                )

                            for match in matching_objects:
                                self.graph.add(
                                    Imports(module, match, self.repository_name),
                                    tx=self.tx,
                                )
                                self.module_dependencies[module].append(match)
                    # ...and if it doesn&#39;t recursively create it
                    else:
                        if imported_object[0].isupper():
                            imported_object = Class(
                                name=imported_object,
                                canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                                repository_name=self.repository_name,
                                inferred=True,
                            )
                        else:
                            imported_object = Function(
                                name=imported_object,
                                canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                                type=str(Function.FunctionType.FUNCTION.value),
                                repository_name=self.repository_name,
                                inferred=True,
                            )

                        source_module, missing = self._calculate_missing_packages(
                            source_module
                        )

                        if source_module == &#34;&#34;:
                            self._create_missing_nodes(missing, import_object=imported_object)
                        elif source_module in self.requirements:
                            self._create_missing_nodes(
                                missing,
                                parent=self.requirements[source_module],
                                import_object=imported_object,
                            )
                        else:
                            self._create_missing_nodes(
                                missing,
                                parent=self.modules[source_module],
                                import_object=imported_object,
                            )

                        self.graph.add(
                            Imports(module, imported_object, self.repository_name),
                            tx=self.tx,
                            graph_name=self.graph_name,
                        )
                        self.module_dependencies[module].append(imported_object)

        # Second pass on unresolved dependencies that are likely to be imports of other modules.
        unresolved = unresolved_dependencies
        while len(unresolved) != 0:
            remaining = []
            for (
                module,
                imported_module,
                imported_object,
                dependency,
            ) in unresolved:
                # Check the module objects of the imported module first
                module_objects = self.module_objects.get(imported_module, [])
                matching_objects = [
                    obj
                    for obj in module_objects
                    if obj is not None and obj.name == imported_object
                ]
                if len(matching_objects) &gt; 0:
                    for match in matching_objects:
                        self.graph.add(
                            Imports(module, match, self.repository_name), tx=self.tx
                        )
                        self.module_dependencies[module].append(match)
                    continue

                # Then check the module imports of the imported module
                module_imports = self.module_dependencies.get(imported_module, [])
                matching_objects = [
                    obj
                    for obj in module_imports
                    if obj is not None and obj.name == imported_object
                ]
                if len(matching_objects) &gt; 0:
                    for match in matching_objects:
                        self.graph.add(
                            Imports(module, match, self.repository_name), tx=self.tx
                        )
                        self.module_dependencies[module].append(match)
                    continue

                remaining.append((module, imported_module, imported_object, dependency))

            if len(remaining) == len(unresolved):
                unresolved = remaining
                break
            else:
                unresolved = remaining

        # Finally, infer any remaining objects
        for (
            module,
            imported_module,
            imported_object,
            dependency,
        ) in unresolved:
            if imported_object.isupper() or imported_object.startswith(&#34;__&#34;):
                imported_object = Variable(
                    name=imported_object,
                    canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                    inferred=True,
                    repository_name=self.repository_name,
                )
            elif imported_object[0].isupper():
                imported_object = Class(
                    name=imported_object,
                    canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                    repository_name=self.repository_name,
                    inferred=True,
                )
            else:
                imported_object = Function(
                    name=imported_object,
                    canonical_name=f&#34;{dependency[&#39;from_module&#39;]}.{dependency[&#39;import&#39;]}&#34;,
                    type=str(Function.FunctionType.FUNCTION.value),
                    repository_name=self.repository_name,
                    inferred=True,
                )

            self.graph.add(
                Contains(imported_module, imported_object, self.repository_name),
                Imports(module, imported_object, self.repository_name),
                tx=self.tx,
                graph_name=self.graph_name,
            )
            self.module_objects[imported_module].append(imported_object)
            self.module_dependencies[module].append(imported_object)

    def _calculate_missing_packages(self, source_module: str) -&gt; Tuple[str, List[str]]:
        &#34;&#34;&#34;Calculates missing packages for a given import source Module.

        Checks both parsed Modules and Repository level requirements.

        Args:
            source_module (str): The canonical name of the source module.

        Returns:
            str: Any pre-existing source package.
            List[str]: Missing packages/modules.
        &#34;&#34;&#34;
        missing = []
        while (
            source_module not in self.modules
            and source_module not in self.requirements
            and source_module != &#34;&#34;
        ):
            parent, child = get_package_parent_and_name(source_module)
            missing.append(child)
            source_module = parent

        return source_module, missing

    def _create_missing_nodes(
        self,
        missing: List[str],
        parent: Package = None,
        import_object: Union[Class, Function] = None,
    ) -&gt; Union[Module, Function]:
        &#34;&#34;&#34;Create missing nodes.

        Args:
            missing (List[str]):
            parent (Package): The parent Package. Optional.
            import_object (Union[Class, Function]): The Class or Function being imported from the

        Returns:
            Union[Module, Function]: The child Node.
        &#34;&#34;&#34;
        nodes = []
        relationships = []
        child = None

        for index, m in enumerate(missing):
            if index == len(missing) - 1 and len(missing) &gt; 1:
                new = Module(
                    name=m, repository_name=self.repository_name, inferred=True
                )
                child = new
            else:
                new = Package(
                    name=m,
                    canonical_name=f&#34;{parent.canonical_name}.{m}&#34; if parent else m,
                    parent_package=parent.canonical_name if parent else &#34;&#34;,
                    external=True,
                    repository_name=self.repository_name,
                    inferred=True,
                )

                if index == len(missing) - 1:
                    child = new

            if parent:
                relationships.append(Contains(parent, new, self.repository_name))

            parent = new
            nodes.append(new)

        # If we have an import_object, but the parent is a Package, we check to see if an __init__
        # module exists for the package. If not, we create an __init__ Module as this is actually
        # where the import_object is being imported from.
        if import_object and parent and isinstance(parent, Package):
            init_name = f&#34;{parent.canonical_name}.__init__&#34;
            if init_name in self.modules:
                parent = self.modules[init_name]
            else:
                new = Module.create_init_module(
                    parent.canonical_name, self.repository_name
                )
                relationships.append(Contains(parent, new, self.repository_name))
                self.modules[init_name] = new
                self.module_dependencies[new] = []
                parent = new

        # If we have an import object, create a Contains relationship with the parent module.
        if import_object:
            relationships.append(Contains(parent, import_object, self.repository_name))
            child = import_object

        if child == None and parent:
            child = parent

        # Add the created nodes and relationships to the Repograph.
        self.graph.add(*nodes, tx=self.tx, graph_name=self.graph_name)
        self.graph.add(*relationships, tx=self.tx, graph_name=self.graph_name)

        return child

    def _parse_call_graph(self, call_graph: Optional[JSONDict]) -&gt; None:
        &#34;&#34;&#34;Parse the call graph extracted by inspect4py.

        Args:
            call_graph (Optional[JSONDict]): The call graph.

        Returns:
            None
        &#34;&#34;&#34;
        if not call_graph:
            log.error(&#34;No call graph provided!&#34;)
            return

        for directory, files in call_graph.items():
            for file_name, file_info in files.items():
                module = self.modules.get(file_name)
                if not module:
                    log.error(&#34;Couldn&#39;t find existing Module node. Skipping!&#34;)
                    continue

                module_objects = self.module_objects.get(module, [])
                module_imports = self.module_imports.get(module, set())
                module_dependencies = self.module_dependencies.get(module, [])

                # Parse body calls
                self._parse_calls(
                    module,
                    file_info.get(&#34;body&#34;, {}),
                    module_objects,
                    module_imports,
                    module_dependencies,
                )

                # For each function described in the call graph, parse these calls
                for function_name, function_calls in file_info.get(
                    &#34;functions&#34;, {}
                ).items():
                    function = find_node_object_by_name(module_objects, function_name)
                    self._parse_calls(
                        module,
                        function_calls,
                        module_objects,
                        module_imports,
                        module_dependencies,
                        caller=function,
                    )

        # Add called builtin functions to the graph
        self.graph.add(
            *self.called_builtin_functions.values(),
            tx=self.tx,
            graph_name=self.graph_name,
        )

    def _parse_calls(
        self,
        parent_module: Module,
        call_info: Optional[JSONDict],
        module_objects: List[any],
        module_imports: Set[str],
        module_dependencies: List[any],
        caller: Optional[Function] = None,
    ) -&gt; None:
        &#34;&#34;&#34;Parse the call graph for a particular module.

        Args:
            parent_module (Module): The parent module.
            call_info (Optional[JSONDict]): The call info.
            caller (Optional[Function): An optional specific function that the call info is for.
        Returns:
            None
        &#34;&#34;&#34;
        if not call_info:
            return

        for call in call_info.get(&#34;local&#34;, []):
            module, function = get_module_and_object_from_canonical_object_name(call)
            matching_objects_in_module = find_node_object_by_name(
                module_objects, function
            )

            # If the call is to an imported function...
            if call in module_imports:
                matching_imports = find_node_object_by_name(module_dependencies, call)
                relationship = Calls(
                    caller if caller else parent_module,
                    matching_imports,
                    self.repository_name,
                )
            # ...or if the call is to a built-in function...
            elif call in PYTHON_BUILT_IN_FUNCTIONS:
                if function in self.called_builtin_functions:
                    function_node = self.called_builtin_functions[function]
                else:
                    function_node = Function(
                        name=function,
                        type=str(Function.FunctionType.FUNCTION.value),
                        builtin=True,
                        repository_name=self.repository_name,
                        inferred=True,
                    )
                    self.called_builtin_functions[function] = function_node

                # Create the relationship between the caller and the new function_node
                relationship = Calls(
                    caller if caller else parent_module,
                    function_node,
                    self.repository_name,
                )

            # ...or if the call is to a function defined in the module
            elif matching_objects_in_module:
                relationship = Calls(
                    caller if caller else parent_module,
                    matching_objects_in_module,
                    self.repository_name,
                )
            else:
                log.debug(&#34;Call to some other variable (%s). Ignoring.&#34;, call)
                relationship = None

            self.graph.add(relationship, tx=self.tx, graph_name=self.graph_name)

    def _parse_extends(self) -&gt; None:
        &#34;&#34;&#34;Parse extends/super class information.

        Returns:
            None
        &#34;&#34;&#34;
        for class_node, module, extends_info in self.extends:
            for extends in extends_info:
                # Check first if the extended class is defined in the module
                matching_objects = [
                    obj
                    for obj in self.module_objects.get(module, [])
                    if
                    obj is not None and
                    (obj.name == extends or obj.canonical_name == extends) and
                    isinstance(obj, Class)
                ]

                if matching_objects:
                    for obj in matching_objects:
                        self.graph.add(
                            Extends(class_node, obj, self.graph_name),
                            tx=self.tx,
                            graph_name=self.graph_name
                        )
                    continue

                # Check if it&#39;s in the module imports
                matching_objects = [
                    obj
                    for obj in self.module_dependencies.get(module, [])
                    if
                    obj is not None and
                    (obj.name == extends or obj.canonical_name == extends) and
                    isinstance(obj, Class)
                ]

                if matching_objects:
                    for obj in matching_objects:
                        self.graph.add(
                            Extends(class_node, obj, self.graph_name),
                            tx=self.tx,
                            graph_name=self.graph_name
                        )
                    continue

                log.warning(&#34;Unable to find extends match&#34;)

    def build(
        self,
        directory_info: Optional[JSONDict],
        call_graph: Optional[JSONDict],
        requirements: List[Requirement] = None,
    ) -&gt; None:
        &#34;&#34;&#34;Build a repograph from directory_info JSON.

        Args:
            directory_info (JSONDict): Directory info JSON.
            call_graph (Optional[JSONDict]): The call graph JSON.
            requirements (List[Requirement], optional): Requirements to pass.

        Returns:
            Repograph

        Raises:
            RepographBuildError
        &#34;&#34;&#34;
        log.info(&#34;Building Repograph...&#34;)

        if not directory_info:
            log.error(&#34;Directory info is empty! Aborting!&#34;)
            raise RepographBuildError(&#34;Directory info is empty&#34;)

        # Pop off non-directory entries from the JSON, for parsing later
        _ = directory_info.pop(&#34;requirements&#34;, None)
        _ = directory_info.pop(&#34;directory_tree&#34;, None)
        licenses = directory_info.pop(&#34;license&#34;, None)
        readmes = directory_info.pop(&#34;readme_files&#34;, None)
        metadata = directory_info.pop(&#34;metadata&#34;, None)
        _ = directory_info.pop(&#34;software_invocation&#34;, None)
        software_type = directory_info.pop(&#34;software_type&#34;, None)
        _ = directory_info.pop(&#34;tests&#34;, None)

        # Create a sorted list of directory paths.py, as dictionaries are not
        # always sortable in Python.
        log.info(&#34;Sorting directories with hierarchical ordering...&#34;)
        directories = sorted(
            list(directory_info.keys()),
            key=lambda file: (os.path.dirname(file), os.path.basename(file)),
        )

        # Parse repository root folder if it exists, otherwise manually create
        # the repository node.
        path = strip_file_path_prefix(directories[0])
        self.repository_name = path

        if is_root_folder(path):
            directory = directories.pop(0)
            repository = self._parse_repository(
                path,
                directory_info=directory_info[directory],
                metadata=metadata,
                software_type=software_type,
            )
        else:
            repository = self._parse_repository(
                get_path_root(path), metadata=metadata, software_type=software_type
            )

        # Parse requirements
        self._parse_requirements(requirements, repository)

        # Parse license
        self._parse_license(licenses, repository)

        # Parse each directory
        log.info(&#34;Extracting information from directories...&#34;)
        for index, directory in enumerate(directories):
            self._parse_directory(
                directory, directory_info[directory], index, len(directories)
            )

        # Retrospectively parse module dependencies
        log.info(&#34;Parsing module dependencies...&#34;)
        self._parse_dependencies()

        # Parse the call list, now that most Nodes should be added to the graph
        log.info(&#34;Parsing call graph...&#34;)
        self._parse_call_graph(call_graph)

        # Parse extends relationships
        log.info(&#34;Parsing extends relationships...&#34;)
        self._parse_extends()

        # Parse READMEs
        self._parse_readme(readmes)

        log.info(&#34;Successfully built a Repograph!&#34;)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="repograph.entities.build.builder.RepographBuilder.build"><code class="name flex">
<span>def <span class="ident">build</span></span>(<span>self, directory_info:Optional[Dict[str,Any]], call_graph:Optional[Dict[str,Any]], requirements:List[requirements.requirement.Requirement]=None) >None</span>
</code></dt>
<dd>
<div class="desc"><p>Build a repograph from directory_info JSON.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>directory_info</code></strong> :&ensp;<code>JSONDict</code></dt>
<dd>Directory info JSON.</dd>
<dt><strong><code>call_graph</code></strong> :&ensp;<code>Optional[JSONDict]</code></dt>
<dd>The call graph JSON.</dd>
<dt><strong><code>requirements</code></strong> :&ensp;<code>List[Requirement]</code>, optional</dt>
<dd>Requirements to pass.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>Repograph</p>
<h2 id="raises">Raises</h2>
<p>RepographBuildError</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def build(
    self,
    directory_info: Optional[JSONDict],
    call_graph: Optional[JSONDict],
    requirements: List[Requirement] = None,
) -&gt; None:
    &#34;&#34;&#34;Build a repograph from directory_info JSON.

    Args:
        directory_info (JSONDict): Directory info JSON.
        call_graph (Optional[JSONDict]): The call graph JSON.
        requirements (List[Requirement], optional): Requirements to pass.

    Returns:
        Repograph

    Raises:
        RepographBuildError
    &#34;&#34;&#34;
    log.info(&#34;Building Repograph...&#34;)

    if not directory_info:
        log.error(&#34;Directory info is empty! Aborting!&#34;)
        raise RepographBuildError(&#34;Directory info is empty&#34;)

    # Pop off non-directory entries from the JSON, for parsing later
    _ = directory_info.pop(&#34;requirements&#34;, None)
    _ = directory_info.pop(&#34;directory_tree&#34;, None)
    licenses = directory_info.pop(&#34;license&#34;, None)
    readmes = directory_info.pop(&#34;readme_files&#34;, None)
    metadata = directory_info.pop(&#34;metadata&#34;, None)
    _ = directory_info.pop(&#34;software_invocation&#34;, None)
    software_type = directory_info.pop(&#34;software_type&#34;, None)
    _ = directory_info.pop(&#34;tests&#34;, None)

    # Create a sorted list of directory paths.py, as dictionaries are not
    # always sortable in Python.
    log.info(&#34;Sorting directories with hierarchical ordering...&#34;)
    directories = sorted(
        list(directory_info.keys()),
        key=lambda file: (os.path.dirname(file), os.path.basename(file)),
    )

    # Parse repository root folder if it exists, otherwise manually create
    # the repository node.
    path = strip_file_path_prefix(directories[0])
    self.repository_name = path

    if is_root_folder(path):
        directory = directories.pop(0)
        repository = self._parse_repository(
            path,
            directory_info=directory_info[directory],
            metadata=metadata,
            software_type=software_type,
        )
    else:
        repository = self._parse_repository(
            get_path_root(path), metadata=metadata, software_type=software_type
        )

    # Parse requirements
    self._parse_requirements(requirements, repository)

    # Parse license
    self._parse_license(licenses, repository)

    # Parse each directory
    log.info(&#34;Extracting information from directories...&#34;)
    for index, directory in enumerate(directories):
        self._parse_directory(
            directory, directory_info[directory], index, len(directories)
        )

    # Retrospectively parse module dependencies
    log.info(&#34;Parsing module dependencies...&#34;)
    self._parse_dependencies()

    # Parse the call list, now that most Nodes should be added to the graph
    log.info(&#34;Parsing call graph...&#34;)
    self._parse_call_graph(call_graph)

    # Parse extends relationships
    log.info(&#34;Parsing extends relationships...&#34;)
    self._parse_extends()

    # Parse READMEs
    self._parse_readme(readmes)

    log.info(&#34;Successfully built a Repograph!&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="repograph.entities.build" href="index.html">repograph.entities.build</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="repograph.entities.build.builder.RepographBuilder" href="#repograph.entities.build.builder.RepographBuilder">RepographBuilder</a></code></h4>
<ul class="">
<li><code><a title="repograph.entities.build.builder.RepographBuilder.build" href="#repograph.entities.build.builder.RepographBuilder.build">build</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>